{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем датасет и подготавливаем, удаляем пустые ячейки, записываем все содержимое поля 'text' в текстовый файл."
      ],
      "metadata": {
        "id": "R67_OCCVmkHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Masking\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "df = pd.read_csv('dataset.csv')\n",
        "df['text'] = df['text'].astype(str)"
      ],
      "metadata": {
        "id": "UC0i1hJ7moac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизируем и преобразовываем текстовые данные в числовые последовательности."
      ],
      "metadata": {
        "id": "-FlweW02m9wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(char_level = True)\n",
        "tokenizer.fit_on_texts(df['text'].values)\n",
        "eos_token = len(tokenizer.word_index)+1\n",
        "tokenizer.word_index['<eos>'] = eos_token\n",
        "vocab_size = eos_token + 1\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(df['text'].values)\n",
        "sequences2 = [ t[1:]+[eos_token] for t in sequences ]\n",
        "padded_sequences = pad_sequences(sequences, padding=\"post\")\n",
        "padded_sequence2 = pad_sequences(sequences2, padding=\"post\")\n",
        "vocab_size = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "OvOqZyT3m-fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded = tf.one_hot(padded_sequences,vocab_size)\n",
        "padded2 = tf.one_hot(padded_sequence2,vocab_size)"
      ],
      "metadata": {
        "id": "vGTPtwttnD-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Строим и обучаем модель."
      ],
      "metadata": {
        "id": "Fyo9TTFTnJ-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Masking(input_shape=(None,vocab_size)))\n",
        "model.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(vocab_size,activation='softmax')))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d9AQNDqnKys",
        "outputId": "fb37d227-c7b3-499a-90b8-7aa945a33d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, None, 69)          0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 256)        202752    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, None, 69)         17733     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 220,485\n",
            "Trainable params: 220,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
        "model.fit(padded, padded2, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rCSJvoNnQKz",
        "outputId": "bc1574b9-6b64-4597-c678-231182a22c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "18/18 [==============================] - 32s 1s/step - loss: 2.2658 - acc: 0.7394\n",
            "Epoch 2/5\n",
            "18/18 [==============================] - 23s 1s/step - loss: 0.8477 - acc: 0.7881\n",
            "Epoch 3/5\n",
            "18/18 [==============================] - 21s 1s/step - loss: 0.7369 - acc: 0.8072\n",
            "Epoch 4/5\n",
            "18/18 [==============================] - 23s 1s/step - loss: 0.7056 - acc: 0.8130\n",
            "Epoch 5/5\n",
            "18/18 [==============================] - 23s 1s/step - loss: 0.6885 - acc: 0.8122\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0654137d00>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сгенерируем текст, начинающийся со слова 'Today', используя обе модели."
      ],
      "metadata": {
        "id": "VSRMm31XyyJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_map = {val:key for key, val in tokenizer.word_index.items()}\n",
        "\n",
        "def decode(x):\n",
        "    return ''.join([reverse_map[t] for t in x])\n",
        "\n",
        "def generate(model,size=100,start='Today '):\n",
        "        inp = tokenizer.texts_to_sequences([start])[0]\n",
        "        chars = inp\n",
        "        for i in range(size):\n",
        "            out = model(tf.expand_dims(tf.one_hot(inp,vocab_size),0))[0][-1]\n",
        "            nc = tf.argmax(out)\n",
        "            if nc==eos_token:\n",
        "                break\n",
        "            chars.append(nc.numpy())\n",
        "            inp = inp + [nc]\n",
        "        return decode(chars)\n",
        "    \n",
        "generate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7T_B-Hlm9RY",
        "outputId": "40b09b87-6d59-4848-a6d6-638ed0313032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todays fecual integrotion armoset and the postlems; insular eroncless. I’ll be goed self what’s nardy to beblembes as “sho believe of a post” understand teuldys like on the renuction our plivided to where deturn was auro afternce. I’m triem.\"\"Not doing the cament. Not anything you sangate miching a need has me them strange things on life yes conlect the problowaver be how compace explay Need some ones the dest I following a prycaptshcle red feelings. are and cownow werway with the didn these internctly whrmend to presenve. ith amplone constech. and the monel-suze unoticle to pe has people the anspagranes 6 becount to some bleads. pery sucemet. You cane to 13% the fissed the reaning and always deph amountiful dadass? I show deedly. reduce. we far. you don’s grow common head. envirunces: module is triff.” the your siscess And their starts will healthy incomm cloume the puring to creating a diffort (necour” But also their storch your term us as a few rescenss the defence ene ycurdonalic try. m\n"
          ]
        }
      ]
    }
  ]
}